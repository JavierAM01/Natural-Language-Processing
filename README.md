# Repositorio de Procesamiento del Lenguaje Natural (NLP)

<img align="right" width="40%" src="images/nlp.png"></img>

¡Bienvenido al repositorio de Procesamiento del Lenguaje Natural (NLP)! Aquí encontrarás una variedad de proyectos relacionados con el NLP, un campo emocionante que se centra en la interacción entre las computadoras y el lenguaje humano.

## Notebooks

En este repositorio, exploraremos una amplia gama de proyectos relacionados con el procesamiento del lenguaje natural. En caso de que un notebook haga uso de algún dataset, se pondrá un link de descarga al mismo o bien estará guardado dentro de la carpeta **data** en su sección correspondiente.  

### Notes 

 - [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)
 - [NLP_conceptos_basicos.ipynb](https://github.com/JavierAM01/Natural-Language-Processing/blob/main/notes/NLP_conceptos_basicos.ipynb)

### Text Classification

 - [Multi class text classification - fine tuning-distilbert.ipynb](https://github.com/JavierAM01/Natural-Language-Processing/blob/main/Text-Classification/Multi%20class%20text%20classification%20-%20fine%20tuning-distilbert.ipynb)
 - [Sentiment Analysis - fine tunning-distilbert.ipynb](https://github.com/JavierAM01/Natural-Language-Processing/blob/main/Text-Classification/Sentiment%20Analysis%20-%20fine%20tunning-distilbert.ipynb)



## Repositories


| Preview | About |
|---------|-------|
| <p align="center">[<img width="3000" height="250" src="https://github.com/JavierAM01/PyTorch-Foundations-Image-Text-Classification/blob/main/images/montage.jpg">](https://github.com/JavierAM01/PyTorch-Foundations-Image-Text-Classification)</p> | **:boom: Basic text classification :boom:** This project serves as an introduction to PyTorch and Weights & Biases (wandb) by implementing and experimenting with deep learning models for image and text classification. The primary objectives include understanding PyTorch’s computation graphs, implementing a basic classifier, logging experiments with wandb, and modifying the baseline model to enhance performance. <p align="center"><a href="https://github.com/JavierAM01/PyTorch-Foundations-Image-Text-Classification">See details</a></p> |
| <p align="center">[<img width="3000" height="250" src="https://github.com/JavierAM01/Generative-Models-of-Text/blob/main/images/GQA_arch_diagram.png">](https://github.com/JavierAM01/Generative-Models-of-Text)</p> | **:boom: Text Generation :boom:** This project explores generative text models, focusing on Recurrent Neural Networks (RNNs) and Transformer-based language models. It involves implementing and experimenting with architectures such as bidirectional RNNs, Transformers, Sliding Window Attention, Rotary Positional Embeddings (RoPE), and Grouped Query Attention (GQA). The goal is to understand how different generative techniques impact language modeling and computational efficiency. <p align="center"><a href="https://github.com/JavierAM01/Generative-Models-of-Text">See details</a></p> |
